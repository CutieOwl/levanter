data: 
- train_urls:
      - "gs://levanter-eu/lakh-data-inter-1024/train.txt"
  validation_urls:
      - "gs://levanter-eu/lakh-data-inter-1024/valid.txt"
  cache_dir: "gs://levanter-eu/lakh-data-inter-1024/cache/"
  tokenizer: "passthrough"
  plaintext: True
  enforce_eos: False
- train_urls:
      - "gs://levanter-eu/lakh-data-inter-16384/train.txt"
  validation_urls:
      - "gs://levanter-eu/lakh-data-inter-16384/valid.txt"
  cache_dir: "gs://levanter-eu/lakh-data-inter-16384/cache/"
  tokenizer: "passthrough"
  plaintext: True
  enforce_eos: False
model:
  type: gpt2
  hidden_dim: 768
  num_heads: 12
  num_layers: 12
  seq_len: [1024, 16384]
  gradient_checkpointing: true
  scale_attn_by_inverse_layer_idx: true
  embed_pdrop: 0.1
  resid_pdrop: 0.1
trainer:
  wandb:
    project: "levanter"
    tags: [ "lakh-data-inter-1024", "gpt2", "lakh-data-inter-16384"]

  mp: p=f32,c=bfloat16
  model_axis_size: [1, 1]
  per_device_parallelism: [-1, 1]

  checkpointer:
    base_path: gs://levanter-eu/lakh-checkpoints/
    save_interval: 30m

  load_checkpoint_path: "gs://levanter-eu/lakh-checkpoints/opo3j88m/step-28000"

  train_batch_size: [512, 32]
  step_curriculum: [20, 3]
  eval_idx: 1
  num_train_steps: 115000
optimizer:
  learning_rate: 6E-4
  weight_decay: 0.1
  min_lr_ratio: 0.1
