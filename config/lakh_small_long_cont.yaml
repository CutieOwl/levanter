data: 
- train_urls:
      - "gs://levanter-eu/lakh-data-inter-16384/train.txt"
  validation_urls:
      - "gs://levanter-eu/lakh-data-inter-16384/valid.txt"
  cache_dir: "gs://levanter-eu/lakh-data-inter-16384/cache/"
  tokenizer: "passthrough"
  plaintext: True
  enforce_eos: False
model:
  type: gpt2
  hidden_dim: 768
  num_heads: 12
  num_layers: 12
  seq_len: [16384]
  gradient_checkpointing: true
  scale_attn_by_inverse_layer_idx: true
  embed_pdrop: 0.1
  resid_pdrop: 0.1
trainer:
  wandb:
    project: "levanter"
    tags: [ "lakh-data-inter-16384", "gpt2"]

  mp: p=f32,c=bfloat16
  model_axis_size: [1]
  per_device_parallelism: [1]

  checkpointer:
    base_path: gs://levanter-eu/lakh-checkpoints/
    save_interval: 30m

  load_checkpoint_path: "gs://levanter-eu/lakh-checkpoints/hy7plh23/step-100000"

  train_batch_size: [32]
  step_curriculum: [1]
  eval_idx: 0
  num_train_steps: 15000
optimizer:
  learning_rate: 1E-5
  weight_decay: 0.1
  min_lr_ratio: 0.1
